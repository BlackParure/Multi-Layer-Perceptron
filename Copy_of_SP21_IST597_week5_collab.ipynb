{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SP21_IST597_week5_collab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# IST597:- Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-3kEaggcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0302a900-6d48-4d0d-b3cf-9db381de46d6"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XlFnwho7D8"
      },
      "source": [
        "# Hyper parameter Setting\n",
        "size_input = 784\n",
        "size_hidden = 256\n",
        "size_output = 10\n",
        "NUM_EPOCHS = 20\n",
        "dropout = False\n",
        "l1 = 0.1\n",
        "l2 = 0.1\n",
        "lr = 0.001\n",
        "dataset = \"fashion_mnist\"\n",
        "# dataset = \"mnist\"\n",
        "regularizer = \"L1L2\"\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "np.random.seed(8888)\n",
        "tf.random.set_seed(8888)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from keras\n",
        "def load_data(dataset, batch_size=20):\n",
        "  if dataset == \"mnist\":\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  elif dataset == \"fashion_mnist\":\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "  x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "  # Split dataset into batches\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "  return [train_ds, test_ds]\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "zWhVHRq8vcjP"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.b1, self.b2]\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "[train_ds, test_ds] = load_data(dataset)\n",
        "with tf.device('gpu:0'):\n",
        "  mlp_on_cpu = MLP(size_input, size_hidden, size_output)\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "\n",
        "  time_start = time.time()\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "    lt = 0\n",
        "    # train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "    # print(len(train_ds))\n",
        "    for images, labels in tqdm(train_ds):\n",
        "      with tf.GradientTape() as tape:\n",
        "        # Cast X to float32\n",
        "        X = images\n",
        "        layer = tf.keras.layers.Dropout(.2)\n",
        "        X_tf = tf.cast(X, dtype=tf.float32)\n",
        "        X_tf = tf.reshape(X_tf, [20,784])\n",
        "        #Remember to normalize your dataset before moving forward\n",
        "        # Compute values in hidden layer\n",
        "        what = tf.matmul(X_tf, mlp_on_cpu.W1) + mlp_on_cpu.b1\n",
        "        hhat = tf.nn.relu(what)\n",
        "        if dropout:\n",
        "          output = layer(tf.matmul(hhat, mlp_on_cpu.W2) + mlp_on_cpu.b2)\n",
        "        else:\n",
        "          output = tf.matmul(hhat, mlp_on_cpu.W2) + mlp_on_cpu.b2 \n",
        "          \n",
        "        if regularizer == \"L1L2\":\n",
        "          loss = loss_object(labels, output)- l1 * tf.math.reduce_sum(abs(X_tf)) - l2 * tf.math.reduce_sum(tf.math.square(X_tf))\n",
        "        else:\n",
        "          loss = loss_object(labels, output)\n",
        "      gradients = tape.gradient(loss, mlp_on_cpu.variables)\n",
        "      optimizer.apply_gradients(zip(gradients, mlp_on_cpu.variables))\n",
        "      train_loss(loss)\n",
        "      train_accuracy(labels, output)\n",
        "    print('Number of Epoch = {} - Average Loss:= {} - Average Accuracy:= {}'.format(epoch + 1, train_loss.result().numpy(), train_accuracy.result().numpy()))\n",
        "    result.append([epoch + 1, train_loss.result().numpy(), train_accuracy.result().numpy()])\n",
        "  time_taken = time.time() - time_start\n",
        "  filename = '{}-{}-{}-{}-{}-{}'.format(dropout, lr, dataset,regularizer, l1, l2)\n",
        "  outfile = open(filename,'wb')\n",
        "  pickle.dump([result, time_taken], outfile)\n",
        "  outfile.close()\n",
        "  print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "  #For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3oEq6tXLfQ7",
        "outputId": "a2cb518d-75de-46cc-b39b-ad9383e3d6b8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:34<00:00, 85.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Loss:= -761.766845703125 - Average Accuracy:= 0.7388666868209839\n",
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 2 - Average Loss:= -764.6197509765625 - Average Accuracy:= 0.7711416482925415\n",
            "Epoch:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:32<00:00, 92.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 3 - Average Loss:= -766.0029296875 - Average Accuracy:= 0.787850022315979\n",
            "Epoch:  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:32<00:00, 93.38it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 4 - Average Loss:= -766.881591796875 - Average Accuracy:= 0.7996249794960022\n",
            "Epoch:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 5 - Average Loss:= -767.5076904296875 - Average Accuracy:= 0.8088499903678894\n",
            "Epoch:  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 6 - Average Loss:= -767.9867553710938 - Average Accuracy:= 0.8164111375808716\n",
            "Epoch:  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:30<00:00, 96.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 7 - Average Loss:= -768.3683471679688 - Average Accuracy:= 0.8228928446769714\n",
            "Epoch:  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 8 - Average Loss:= -768.6846923828125 - Average Accuracy:= 0.8286041617393494\n",
            "Epoch:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 96.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 9 - Average Loss:= -768.9495849609375 - Average Accuracy:= 0.8335444331169128\n",
            "Epoch:  9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:41<00:00, 73.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 10 - Average Loss:= -769.1743774414062 - Average Accuracy:= 0.8380699753761292\n",
            "Epoch:  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 96.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 11 - Average Loss:= -769.3710327148438 - Average Accuracy:= 0.8422242403030396\n",
            "Epoch:  11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 12 - Average Loss:= -769.5438232421875 - Average Accuracy:= 0.846095860004425\n",
            "Epoch:  12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:32<00:00, 92.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 13 - Average Loss:= -769.69677734375 - Average Accuracy:= 0.8496551513671875\n",
            "Epoch:  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:41<00:00, 73.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 14 - Average Loss:= -769.8325805664062 - Average Accuracy:= 0.852990448474884\n",
            "Epoch:  14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:48<00:00, 61.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 15 - Average Loss:= -769.9542846679688 - Average Accuracy:= 0.856166660785675\n",
            "Epoch:  15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:21<00:00, 36.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 16 - Average Loss:= -770.0634155273438 - Average Accuracy:= 0.8590999841690063\n",
            "Epoch:  16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:50<00:00, 59.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 17 - Average Loss:= -770.1614990234375 - Average Accuracy:= 0.8618245124816895\n",
            "Epoch:  17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:22<00:00, 36.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 18 - Average Loss:= -770.2503051757812 - Average Accuracy:= 0.8643962740898132\n",
            "Epoch:  18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:41<00:00, 73.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 19 - Average Loss:= -770.3305053710938 - Average Accuracy:= 0.8669579029083252\n",
            "Epoch:  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:31<00:00, 95.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 20 - Average Loss:= -770.4050903320312 - Average Accuracy:= 0.8692799806594849\n",
            "\n",
            "Total time taken (in seconds): 800.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9c988a-7a55-4648-bbb2-ebf14911142c"
      },
      "source": [
        "# Test on Testset \n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "#test_loss_total = 0.0\n",
        "for images, labels in tqdm(test_ds):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Cast X to float32\n",
        "    X = images\n",
        "    layer = tf.keras.layers.Dropout(.2)\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    X_tf = tf.reshape(X_tf, [20,784])\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer\n",
        "    what = tf.matmul(X_tf, mlp_on_cpu.W1) + mlp_on_cpu.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    if dropout:\n",
        "      output = layer(tf.matmul(hhat, mlp_on_cpu.W2) + mlp_on_cpu.b2)\n",
        "    else:\n",
        "      output = tf.matmul(hhat, mlp_on_cpu.W2) + mlp_on_cpu.b2 \n",
        "      \n",
        "    if regularizer == \"L1L2\":\n",
        "      loss = loss_object(labels, output)- l1 * tf.math.reduce_sum(abs(X_tf)) - l2 * tf.math.reduce_sum(tf.math.square(X_tf))\n",
        "    else:\n",
        "      loss = loss_object(labels, output)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(labels, output)\n",
        "print('Test Result - Average Loss:= {} - Average Accuracy:= {}'.format(test_loss.result().numpy(), test_accuracy.result().numpy()))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:03<00:00, 148.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result - Average Loss:= -771.993896484375 - Average Accuracy:= 0.8416000008583069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "infile = open(\"/content/False-0.001-fashion_mnist-L1L2-0.1-0.1\",'rb')\n",
        "new_dict = pickle.load(infile)\n",
        "infile.close()\n",
        "x=[]\n",
        "y_loss=[]\n",
        "z_acc=[]\n",
        "print(new_dict[1])\n",
        "for i in new_dict[0]:\n",
        "  x.append(i[0])\n",
        "  y_loss.append(i[1])\n",
        "  z_acc.append(i[2])\n",
        "plt.plot(x, y_loss, label = \"Epoch vs Loss\")\n",
        "# plt.plot(x, z_acc, label = \"Epoch vs Acc\")\n",
        "\n",
        "plt.xlabel('x - Epoch')\n",
        "# plt.ylabel('y - Acc')\n",
        "plt.ylabel('y - Loss')\n",
        "plt.title('Loss Graph for Fashion FMNIST')\n",
        "# plt.title('Acc Graph for Fashion FMNIST')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "# train_variance = [770.383, 770.677, 770.214, 770.437, 770.368, 770.570, 770.313, 770.374, 770.405, 770.517]\n",
        "# test_variance = [772.490, 772.624, 772.049, 772.451, 772.399, 772.587, 772.256, 772.161, 771.993, 771.863]\n",
        "# plt.scatter(x, test_variance, label = \"Test_Variance\")\n",
        "# plt.title('Variance Graph for Fashion FMNIST in Testing')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "AL2tRYJxPavT",
        "outputId": "fd3a7717-1705-49c8-899a-993a639b01e6"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}